{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72YlsvSQgcTl"
      },
      "source": [
        "# RAG QA Bot - OpenAI + Pinecone + Streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BWwnC3bigcTn",
        "outputId": "45026f65-4b28-4c4c-9549-59aa15dfcf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.0)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.6.15)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pinecone streamlit PyPDF2 python-docx tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2068ffd2"
      },
      "source": [
        "import os\n",
        "import openai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import PyPDF2\n",
        "import docx\n",
        "import tiktoken\n",
        "import hashlib\n",
        "import time\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
        "INDEX_NAME = 'rag-qa-index'\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "if INDEX_NAME not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=1536,\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(cloud='gcp', region='gcp-starter')\n",
        "    )\n",
        "    while not pc.describe_index(INDEX_NAME).status['ready']:\n",
        "        time.sleep(1)\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith('.pdf'):\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            return '\\n'.join([page.extract_text() for page in reader.pages])\n",
        "    elif file_path.endswith('.docx'):\n",
        "        doc = docx.Document(file_path)\n",
        "        return '\\n'.join([para.text for para in doc.paragraphs])\n",
        "    elif file_path.endswith('.txt'):\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "             return file.read()\n",
        "\n",
        "def chunk_text(text, chunk_size=800):\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    sentences = text.split('.')\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        potential_chunk = current_chunk + sentence + \".\"\n",
        "        if len(encoding.encode(potential_chunk)) <= chunk_size:\n",
        "            current_chunk = potential_chunk\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \".\"\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "def get_embedding(text):\n",
        "    response = openai.embeddings.create(model='text-embedding-3-small', input=text)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def store_document(chunks, doc_name):\n",
        "    vectors = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_id = hashlib.md5(f\"{doc_name}_{i}\".encode()).hexdigest()\n",
        "        embedding = get_embedding(chunk)\n",
        "        vectors.append({\n",
        "            'id': chunk_id,\n",
        "            'values': embedding,\n",
        "            'metadata': {'text': chunk, 'document': doc_name}\n",
        "        })\n",
        "    for i in range(0, len(vectors), 100):\n",
        "        index.upsert(vectors=vectors[i:i+100])\n",
        "    return len(chunks)\n",
        "\n",
        "def query_docs(query, top_k=3):\n",
        "    query_embedding = get_embedding(query)\n",
        "    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
        "    return [match['metadata']['text'] for match in results['matches']]\n",
        "\n",
        "def generate_answer(query):\n",
        "    context_docs = query_docs(query)\n",
        "    context = '\\n\\n'.join(context_docs)\n",
        "    prompt = f\"\"\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer based on the context:\"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=[{'role': 'user', 'content': prompt}],\n",
        "        max_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d34cae3"
      },
      "source": [
        "def ask_rag_bot(query):\n",
        "    return generate_answer(query)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9780197d",
        "outputId": "1ae9cfa5-5317-43df-c84e-72e08773fa95"
      },
      "source": [
        "def main():\n",
        "    sample_doc_path = 'sample_document.txt'\n",
        "    print(f\"Processing document: {sample_doc_path}\")\n",
        "    try:\n",
        "        document_text = extract_text(sample_doc_path)\n",
        "        document_chunks = chunk_text(document_text)\n",
        "        num_chunks_stored = store_document(document_chunks, os.path.basename(sample_doc_path))\n",
        "        print(f\"Processed and stored {num_chunks_stored} chunks from {sample_doc_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing document: {e}\")\n",
        "        return\n",
        "    print(\"-\" * 30)\n",
        "    query = \"What are the benefits of a RAG system?\"\n",
        "    print(f\"Asking question: {query}\")\n",
        "    try:\n",
        "        answer = ask_rag_bot(query)\n",
        "        print(f\"Answer: {answer}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying RAG bot: {e}\")\n",
        "main()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing document: sample_document.txt\n",
            "Processed and stored 1 chunks from sample_document.txt\n",
            "------------------------------\n",
            "Asking question: What are the benefits of a RAG system?\n",
            "Answer: A RAG (Red, Amber, Green) system is a visual management tool used to quickly assess and communicate the status of different tasks or projects. The benefits of a RAG system include improved transparency, increased accountability, better decision-making, and enhanced communication among team members. It allows for quick identification of areas that need attention or intervention, helping teams stay on track and achieve their goals more effectively.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}